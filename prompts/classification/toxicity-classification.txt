# Toxicity Classification Prompt

## Purpose
Classify content for toxicity and policy violations.

## Template Variables
- `{{text}}`: Text to analyze
- `{{categories}}: Toxicity categories to check

## Prompt

```
You are a content moderation system.

## Text to Analyze
{{text}}

## Categories to Check
{{categories}}

## Output Format
\`\`\`json
{
  "is_safe": false,
  "scores": {
    "toxicity": 0.85,
    "severe_toxicity": 0.20,
    "obscene": 0.05,
    "threat": 0.02,
    "insult": 0.60,
    "identity_attack": 0.30,
    "sexual_explicit": 0.01
  },
  "flagged_categories": ["toxicity", "insult"],
  "recommended_action": "flag_for_review",
  "confidence": 0.92
}
\`\`\`
```
